## Performance & Scaling Strategy: The "Reliable-Fast" Mechanism

This document addresses potential performance concerns regarding the SQLite-backed Outbox and Shadow Controller architecture. While database-backed messaging is often perceived as "slow," our implementation utilizes several low-level optimizations to ensure high throughput and sub-millisecond overhead for business-critical workflows.

---

### 1. Eliminating Disk Bottlenecks: SQLite Optimization

Writing to disk is the most expensive operation. We bypass the traditional "slow" database bottlenecks through specific configuration:

* **WAL (Write-Ahead Logging) Mode:** By default, database writes lock the entire file. We use `PRAGMA journal_mode=WAL;`, which allows the **Service** (the Writer) and the **Dispatcher** (the Reader) to operate simultaneously without contention.
* **Synchronous "Normal" Mode:** We set `PRAGMA synchronous=NORMAL;`. In WAL mode, this provides a massive speed boost while remaining robust against application crashes. Data is flushed to disk at the optimal time by the OS.
* **Connection Pooling:** The `Workflow.Client` maintains a dedicated, long-lived connection to the SQLite file to avoid the overhead of opening/closing file handles on every call.

---

### 2. Reducing Latency: The "Signaling" Dispatcher

A common mistake in Outbox patterns is "polling" (checking the DB every second). This introduces unnecessary latency. We use an **In-Memory Signaling** approach:

1. **The Write:** The Service writes the call to SQLite.
2. **The Signal:** Immediately after the write, the library triggers a `System.Threading.Channels` signal or a `SemaphoreSlim`.
3. **The Execution:** The Background Dispatcher wakes up **instantly** (within microseconds) to process the new row.
4. **The Safety Net:** A "fallback" poll runs every 30 seconds only to catch any edge cases where a signal might have been missed (e.g., during a service restart).

> **Result:** Message latency is determined by network speed, not database polling intervals.

---

### 3. Execution Speed: Source-Generated vs. Reflection

Standard WebAPI and gRPC frameworks often rely on Reflection to find controllers and methods at runtime, which consumes CPU.

* **Static Mapping:** Our **Shadow Controllers** are generated as static C# code. When an Engine call hits the Service, the routing logic is a simple, compiled `switch` statement.
* **Minimal Pipeline:** The Shadow Controllers bypass the heavy MVC "Filter/Action" pipeline. They are registered as **Minimal API** endpoints, resulting in the lowest possible memory and CPU footprint per request.

---

### 4. Scalability Metrics

For the vast majority of business applications, this architecture scales far beyond requirements:

| Scenario | Performance Impact |
| --- | --- |
| **Transaction Latency** | **+2ms to 5ms** (The time it takes to write one SQLite row). |
| **Throughput** | **500â€“2,000 calls per second** per service instance (standard SSD). |
| **Engine Overhead** | **<1ms** (Indexed GUID check in the Deduplication table). |

---

### 5. When to Scale Further

If a specific service requires extreme scale (e.g., >5,000 calls/second), the architecture allows for a "Plug-and-Play" upgrade:

* The `Workflow.Client` can be configured to use an **In-Memory SQLite** instance or **Redis** as the Outbox provider.
* The "Shadow Controller" logic remains identical; only the storage provider changes.

### Summary

This approach provides **Reliable-Fast** performance. We are trading a negligible amount of raw speed (the few milliseconds for an SQLite write) for **100% data integrity**. In a workflow engine, a call that is 2ms slower is acceptable; a call that is lost is a catastrophe.
